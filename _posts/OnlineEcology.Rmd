---
title: "Online ecology"
author:
  - David Beauchesne, Kévin Cazelles & Rémi Daigle
status: draft
date: "`r paste0('June 19, 2017  -  last update on ', format(Sys.time(), '%B %d, %Y'))`"
output:
  html_document:
    include:
        after_body: [footer.html, disqus.html]
---

<br/>

Status: ![](https://img.shields.io/badge/letiR-InDevelopment-blue.svg)

<!-- render(input = './_posts/OnlineEcology.rmd', 'html_document') -->

```{r, include = FALSE}
rm(list=ls())
library(raster)
```

<br/>

## Setting up R

#### R version used to build the last update of this post

```{r infosession}
sessionInfo()[[1]]$version.string
```

<br/><br/>

# IMAGINE!

Let's imagine that you are interested in a species in a given area and wish to know as much as possible about it. But, you can't go out in the field because funding is running short. What you do have, however, is a certain knowledge of the tools that are available to you and you are wondering how far they can take you. Let's find out.

<br/>

## Defining species and area of interest

```{r, params}
# Let's select Atlantic cod as our species of interest
    sp <- 'Gadus morhua'

# And the gulf of St. Lawrence as our study area
# Extent:
    latmax <- 52.01312
    latmin <- 45.52399
    lonmax <- -55.73636
    lonmin <- -71.06333

# Create a spatial bounding box for the area of interest using the 'sf' package:
# create a matrix:
    bbmat <- cbind(c(lonmin,lonmax,lonmax,lonmin,lonmin),
                   c(latmin,latmin,latmax,latmax,latmin)
                   )
# 2. Make the matrix a 'simple features' polygon:
    bbsf <- sf::st_polygon(list(bbmat))

# and let's give it information about the projection:
    bbsfc <- sf::st_sfc(bbsf,crs="+proj=longlat +datum=WGS84")

# finally, let's make it a simple features data.frame:
    bb <- sf::st_sf(name="Study Site",geometry=bbsfc)
```

<br/>

## Describe your species

### Fishbase

We'll start with a description of the species. First, let's see what [fishbase](http://www.fishbase.ca/) has to offer. This online data repository, along with [sealifebase](http://www.sealifebase.org/), contains a lot of information on marine and aquatic species all over the world and is accessible through the package [`rfishbase`](https://github.com/ropensci/rfishbase)

<br/>

```{r, ecology, eval = TRUE}
# Let's have a look at the information available on our species ecology
ecol <- rfishbase::ecology(sp)
ecol <- cbind(colnames(ecol), t(ecol))
rownames(ecol) <- NULL
ecol <- ecol[ecol[,2] != 0, ] # remove 0
ecol <- ecol[!is.na(ecol[,2]), ] # remove NAs

knitr::kable(ecol, col.names = c('Descriptors', 'Attributes'))
```

<br/>

### Taxize

We can also extract taxonomic informations rather easily. The package [taxize](https://ropensci.org/tutorials/taxize_tutorial.html) allows you to extract and validate, among other things, the taxonomy of millions of species by accessing an important number of online databases accessible through their Application Program Interface (API).

<br/>

```{r, taxonomy, eval = TRUE, message = FALSE}
# Start by exporting the taxonomy of our species
    knitr::kable(taxize::classification(sp, db = 'worms', verbose = FALSE)[[1]])

# We can also extract the common or scientific names using sci2comm() & comm2sci(), respectively.
    taxize::sci2comm(sp, db = 'itis')

# Or find out whether there are other names under which the species is known
    taxize::synonyms(sp, db = 'itis')

# Another really interesting feature is to extract all known species at a given taxonomic scale.
# Let's take the genus level and see the first 20 species that are part of that genus on the itis database
    knitr::kable(taxize::children(strsplit(sp, ' ')[[1]][1], db = 'itis')[[1]])
```

<br/>

### GloBI

How about extracting all known preys and predators of the species of interest? The [Global Biotic Interactions](http://globalbioticinteractions.org) web platform contains thousands of empirical binary interactions for multiple types of interactions, all over the world, and is easily accessible using the package [rglobi](https://github.com/ropensci/rglobi).

<br/>

```{r, trophic, eval = TRUE}
# There are multiple types of interactions available on GloBI
    knitr::kable(rglobi::get_interaction_types()[,1:3])

# For now let's focus on predator-prey interactions
    prey <- rglobi::get_prey_of(sp)$target_taxon_name
    pred <- rglobi::get_predators_of(sp)$target_taxon_name
    length(prey)
    length(pred)
    prey[1:20]
    pred[1:20]
```

<br/>

## Make your search spatially explicit

### Get data from OBIS

OBIS is the [Ocean Biogeographic Information System](http://www.iobis.org/) and their vision is: "To be the most comprehensive gateway to the world’s ocean biodiversity and biogeographic data and information required to address pressing coastal and world ocean concerns." We can get access to their HUGE database through the excellent `robis` package by [ropensci](https://ropensci.org/)

<br/>

```{r, OBIS data, eval=TRUE}
# Download occurrence data for species and area of interest between 2010 and 2017
    OBIS <- robis::occurrence(scientificname = sp, geometry=sf::st_as_text(bb$geometry), startdate = as.Date("2010-01-01"), enddate = as.Date("2017-01-01"), fields = c("species", "yearcollected","decimalLongitude", "decimalLatitude"))

# remove duplicates
    OBIS <- unique(OBIS)

# Transform as spatial file
    OBIS <- sf::st_as_sf(OBIS,
                     coords = c("decimalLongitude", "decimalLatitude"),
                     crs="+proj=longlat +datum=WGS84",
                     remove=FALSE)

# Visuzlize with mapview
    mapview::mapview(OBIS, cex = 4)@map
```

<br/>

## Environmental variables

There are multiple resources available to access environmental data directly through R. Bathymetry data can easily be accessed using the `marmap` package. Other environmental data can also be accessed using other packages like `raster` for terrestrial climatic data (bioclim) and `rnoaa` for some environmental layers like sea surface temperature et sea ice cover. Finally, a precious resource is the recently published `sdmpredictors` package, which provides access to multiple important global environmental datasets for marine and terrestrial environments and a total of `r nrow(sdmpredictors::list_layers(sdmpredictors::list_datasets()))`

<br/>

```{r, sdmpredictors}
knitr::kable(sdmpredictors::list_datasets())
```

<br/>

We can then import environmental data using `sdmpredictors`. Since our study area of interest is marine, we will select environmental variables accordingly from the `Bio-ORACLE` dataset, although data from `MARSPEC` could also be used.


<br/>

```{r, importEnvVarhidden, echo = FALSE, eval = TRUE}
# Import marine layers
    layers <- c('BO_chlomean','BO_dissox','BO_ph','BO_salinity','BO_sstmean','BO_bathymean')
    ##
    envCov <- readRDS("assets/envCov.Rds")
    ##
    vec_fl <- paste0("./_tmp/", c(
        "BO_bathymean_lonlat.tif", "BO_chlomean_lonlat.tif",
        "BO_dissox_lonlat.tif",    "BO_ph_lonlat.tif",
        "BO_salinity_lonlat.tif",  "BO_sstmean_lonlat.tif"
        ))
    ##
    if (all(file.exists(c("_tmp/envCov.Rds", vec_fl)))) {
      envCov <- readRDS("./_tmp/envCov.Rds")
    } else  {
      envCov <- sdmpredictors::load_layers(layers, datadir = paste0( getwd(), "/_tmp"), rasterstack = TRUE)
      saveRDS(envCov, "./_tmp/envCov.Rds")
    }


```

```{r, importEnvVar, eval = TRUE}
# Import marine layers
    layers <- c('BO_chlomean','BO_dissox','BO_ph','BO_salinity','BO_sstmean','BO_bathymean')
    # layers <- 'BO_ph'
    envCov <- sdmpredictors::load_layers(layers, datadir = paste0( getwd(), "/_tmp"), rasterstack = TRUE)
```

Clip them and plot them:

```{r, plotEnvVar, eval = TRUE}
# Clip to study area extent
    envCov <- raster::crop(envCov, raster::extent(lonmin, lonmax, latmin, latmax))
    envCov <- raster::stack(envCov)

# Data description
    knitr::kable(sdmpredictors::get_layers_info(layers)$current[,1:4])

# Plot 'em!
    raster::plot(envCov)
```

<br/>

## Species distribution models

Now what we can do once we have species occurrence data and environmental variables are species distribution models (SDMs). There are multiple ways and packages to perform SDMs and this [vignette](https://cran.r-project.org/web/packages/dismo/vignettes/sdm.pdf) provides an extensive overview of the different methods available. For this workshop, we will be using the package `biomod2`, which implements most of the methods presented in the vignette. There is also a thorough explanation of our to use `biomod2` in another very interesting [vignette](https://r-forge.r-project.org/scm/viewvc.php/*checkout*/pkg/biomod2/inst/doc/Simple_species_modelling.pdf?root=biomod)

<br/>

### Formating data

The first thing to do is to format our data to be able to work with `biomod2` functions, which work with BIOMOD.formated.data.PA class objects. This entails stacking all of our environmental data together to perform analyses, which was performed in the previous step using the `sdmpredictors` package. You can then create your `biomod2` data class.

<br/>

```{r, SDM data, eval = TRUE, results = 'hide'}
SDMdata <- biomod2::BIOMOD_FormatingData(resp.var = rep(1,nrow(OBIS)),
                                        expl.var = envCov,
                                        resp.xy = data.frame(OBIS$decimalLongitude, OBIS$decimalLatitude),
                                        resp.name = sp,
                                        PA.nb.rep = 1)
```

<br/>

...and use this object with the `biomod2` functions are generate a distribution model for your species of interest.

<br/>

```{r, SDM model, eval = TRUE, results = 'hide', warning = FALSE}
# Basic options for modelling
    SDMoption <- biomod2::BIOMOD_ModelingOptions()

# SDM model
    SDM <- biomod2::BIOMOD_Modeling(data = SDMdata,
                                    models = "MAXENT.Tsuruoka",
                                    model.options = SDMoption,
                                    SaveObj = FALSE)
```

<br/>

You can then extract the evaluation of the fit of your model

<br/>

```{r, modelEval}
# Model evaluation
    knitr::kable(biomod2::get_evaluations(SDM))
```

<br/>

Finally, once the models are calibrated and evaluated, you can project your species spatial distribution...

<br/>

```{r, sdmSpatial, results = 'hide'}
# Model spatial projection
    SDMproj <- biomod2::BIOMOD_Projection(modeling.output = SDM,
                                          new.env = envCov,
                                          proj.name = 'Awesome!',
                                          selected.models = 'all',
                                          binary.meth = 'TSS',
                                          compress = 'xz',
                                          clamping.mask = F,
                                          output.format = '.grd')
# ... and visualize them!
    biomod2::plot(SDMproj)
```

<br/>

Riveting! We starting with a basic idea and ended up with a species description, an idea of the distribution of certain environmental parameters in our area of interest (could be better, we know!) and the potential spatial distribution of our species!

...but should we stop there?

The reality is, there is so much more going on in our area of interest than the spatial distribution of a single species. Let's see what other insights we an get from available open source resources.


<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

<!--


<br/>

## Community level analyses

One of the usual challenge in ecology is to perform analyses at the community scale often due to the difficulty of sampling multiple species in a single system. The reality is that our species of interest is very likely to interact and be impacted by other species.

<br/>

### Extract all occurrence known occurrence data in area of interest

OBIS once again gives us the opportunity to access multiple species occurrences. Let's go back to OBIS and extract every available data in our system.

```{r, multi species OBIS, eval = FALSE}
# Load all known species occurrences from our area of interest
    multiOBIS <- robis::occurrence(geometry=st_as_text(bb$geometry), startdate = as.Date("2010-01-01"), enddate = as.Date("2017-01-01"), fields = c("species", "yearcollected","decimalLongitude", "decimalLatitude"))
    multiOBIS <- multiOBIS[!is.na(multiOBIS[,'species']), ] # remove species == NA

# Remove duplicates
    multiOBIS <- unique(multiOBIS)

# Select species for which there is at least n observations
    n = 50
    spOK <- names(which(table(multiOBIS[,'species']) >= n)) # id of species with at least n observations
    multiOBIS <- multiOBIS[multiOBIS[, 'species'] %in% spOK, ] # Subset of multiOBIS data with species with at least n observations
    multiOBIS[,'species'] <- as.factor(multiOBIS[,'species'])
    multiOBIS[,'yearcollected'] <- as.factor(multiOBIS[,'yearcollected'])
    write.csv(multiOBIS,'multiOBIS.csv',row.names = FALSE)
```

<br/>

```{r, multiOBISPlot, eval = FALSE}
# Read occurrence data file
    multiOBIS <- read.csv("multiOBIS.csv")

# Structure of object
    str(multiOBIS)

# Species list
    spList <- unique(multiOBIS[,'species'])
    length(spList)

# Plot
    multiOBIS <- sf::st_as_sf(multiOBIS,
                     coords = c("decimalLongitude", "decimalLatitude"),
                     crs="+proj=longlat +datum=WGS84",
                     remove=FALSE) %>%
        filter(!is.na(species))

    ggplot(multiOBIS) +
        geom_raster(data=bathyras,aes(x=x,y=y,fill=z))+
        geom_sf(data=bb,fill="transparent",colour='yellow',size=2)+
        geom_point(data=multiOBIS,aes(x=decimalLongitude,y=decimalLatitude))+
        coord_sf(xlim = c(lonmin-x,lonmax+x),
                 ylim = c(latmin-x,latmax+x),
                 expand = F)

# mapview again
    multiOBIS <- read.csv("./multiOBIS.csv")
    proj <- "+proj=longlat +datum=WGS84"
    multiOBISpt <- sp::SpatialPointsDataFrame(coords = multiOBIS[, c("decimalLongitude", "decimalLatitude")], data = multiOBIS, proj4string = CRS(proj), match.ID = TRUE)

    mapview::mapviewOptions(maxpoints = 40000)
    mapview::mapview(multiOBISpt, cex = 4, zcol = 'species')@map

```

<br/>

### Trophic network

Using `rglobi` once more, we can extract all known interactions between all species for which we obtained data from OBIS.

<br/>

```{r, interaction matrix, eval = FALSE}
    nsp <- length(spList)
    foodWeb <- matrix(ncol = nsp, nrow = nsp, data = 0, dimnames = list(spList, spList))

    pb <- txtProgressBar(min = 0,max = nsp, style = 3)
    for(i in 1:nsp) {
        for(j in 1:nsp) {
            inter <- rglobi::get_interactions_by_taxa(sourcetaxon = spList[i], targettaxon = spList[j], interactiontype = 'eats')
            if(nrow(inter) > 0) foodWeb[j,i] <- 1
        }
    setTxtProgressBar(pb, i)
    }
    close(pb)

    saveRDS(foodWeb, file = './foodWeb.rds')
```

<br/>

We can now visualize the network using the package iGraph...

```{r, foodWeb, eval = FALSE}
    nsp <- length(spList)
    foodWeb <- readRDS('./foodWeb.rds')

    netw <-  igraph::graph_from_adjacency_matrix(t(foodWeb))

    vec_col <- spList
    vec_col[vec_col != sp] <- "#11bdec"
    vec_col[vec_col == sp] <- "#cc154b"


    plot(netw,
      vertex.color = vec_col,
      vertex.frame.color = "transparent",
      vertex.label.color = "black",
      edge.arrow.size = .5
      )
```

<br/>

... which does not render well visually when there are too many species. We can however do this better (and more fun!) using the package networkD3

<br/>

```{r, d3network, eval = FALSE}

netwD3 <- networkD3::igraph_to_networkD3(netw, group = vec_col, what = 'both')
nodeSize <- spList
nodeSize[nodeSize != sp] <- 2
nodeSize[nodeSize == sp] <- 4
netwD3$nodes <- cbind(netwD3$nodes, nodeSize)

networkD3::forceNetwork(Links = netwD3$links,
                        Nodes = netwD3$nodes,
                        Source = 'source',
                        Target = 'target',
                        NodeID = 'name',
                        Group = 'group',
                        zoom = TRUE,
                        linkDistance = 50,
                        fontSize = 12,
                        opacity = 0.9,
                        charge = -20,
                        # colourScale = networkD3::JS('d3.scale.ordinal().range(vec_col)'),
                        Nodesize = 'nodeSize')

```

<br/>

### Co-distribution

We could also evaluate how species are co-distributed using an analysis analog to SDMs, but at the communicty scale and using a hierarchical Bayesian approach, Hierarchical Modeling of Species Communities (HMSC) currently being implemented in R in the package [`HMSC`](https://github.com/guiblanchet/HMSC). As with SDM using the `biomod2` package, the first step is to format the data into a HMSC class object.


<br/>

##### Create regular grid over study area

In order to create common observations among individual observations, we will aggregate all data within regular grid cells, so that cells will become planning units on which we base co-distribution of species. We will also create a rather coarse sized grid in order to make processing speed more efficient. Of course there would be more sophisticated ways to do this, but for simplicity's sake we will perform a simple intersect between the grid and occurrence data.

<br/>

```{r, gridFunction, eval = FALSE}
# First create a function to generate hexagonal grids
    hexGrid <- function(size, shp_over) {
        library(rgeos)
        library(sp)
        shp_over2 <- gBuffer(shp_over, width = size) # buffer so that whole surface of shapefile is covered by a cell
        spat_grid <- spsample(shp_over2,type="hexagonal",cellsize=size, offset=c(0,0)) # creating points for a hex grid
        spat_grid <- HexPoints2SpatialPolygons(spat_grid) # creating polygons
        proj4string(spat_grid) <- proj4string(shp_over) # set projection
        spat_grid <- spat_grid[shp_over, ] # clipping grid to retain only cells intersecting shapefile

        id <- paste('ID',seq(1:length(spat_grid)), sep = '')
        row.names(spat_grid) <- id
        spat_grid <- SpatialPolygonsDataFrame(Sr = spat_grid, data = data.frame(ID = id, row.names = id))

        return(spat_grid)
    }

# Load shapefile over which grid is made
    egsl <- rgdal::readOGR(dsn = "./", layer = "egsl")

# Create grid
    egsl_grid <- hexGrid(size = 10000, shp_over = egsl)
    rgdal::writeOGR(egsl_grid, dsn = './', layer = 'egsl_grid', driver="ESRI Shapefile", overwrite_layer=TRUE)

# Plot grid
    plot(egsl_grid)
```

<br/>

```{r, plotGrid, eval = FALSE, message = FALSE}
# Plot grid
    egsl_grid <- rgdal::readOGR(dsn = "./", layer = "egsl_grid")
    proj <- "+proj=longlat +datum=WGS84"
    egsl_grid <- sp::spTransform(egsl_grid, CRSobj = CRS(proj))
    plot(egsl_grid)
```

<br/>

##### Intersect occurrences and environmental data with grid

<br/>

```{r, occGrid, eval = FALSE}
# reload multiOBIS data and transform into sp points
    multiOBIS <- read.csv("multiOBIS.csv")
    proj <- "+proj=longlat +datum=WGS84"
    multiOBISpt <- sp::SpatialPointsDataFrame(coords = multiOBIS[, c("decimalLongitude", "decimalLatitude")], data = multiOBIS, proj4string = CRS(proj), match.ID = TRUE)

# Overlay occurrences on grid
    occGrid <- sp::over(multiOBISpt, egsl_grid)
    multiOBIS <- cbind(multiOBIS, occGrid)
    multiOBIS_wide <- reshape2::dcast(multiOBIS, formula = ID ~ species, value.var = 'species', fun.aggregate = length)

    for(i in 2:ncol(multiOBIS_wide)) {
        for(j in 1:nrow(multiOBIS_wide)) {
            if(multiOBIS_wide[j,i] > 1) multiOBIS_wide[j,i] <- 1
        }
    }

    toAdd <- egsl_grid@data[,'ID'][!egsl_grid@data[,'ID'] %in% multiOBIS[,'ID']]
    matSup <- matrix(nrow = length(toAdd), ncol = ncol(multiOBIS_wide), dimnames = list(c(), colnames(multiOBIS_wide)), data = 0)
    matSup[,'ID'] <- toAdd
    multiOBIS_wide <- rbind(multiOBIS_wide, matSup)
    multiOBIS_wide <- multiOBIS_wide[-which(is.na(multiOBIS_wide[,'ID']) == T), ]
    egsl_grid@data <- merge(egsl_grid@data, multiOBIS_wide, by = 'ID')
    spAll <- colnames(egsl_grid@data)[2:ncol(egsl_grid@data)]
    spID <- seq(1:length(spAll))
    colnames(egsl_grid@data)[2:ncol(egsl_grid@data)] <- spID

# Extract environmental values from rasters
    egsl_grid@data <- cbind(egsl_grid@data, raster::extract(bathypoly, egsl_grid, fun = mean, na.rm = T))
    colnames(egsl_grid@data)[ncol(egsl_grid@data)] <- 'bathy'
    egsl_grid@data <- cbind(egsl_grid@data, raster::extract(sst2, egsl_grid, fun = mean, na.rm = T))
    colnames(egsl_grid@data)[ncol(egsl_grid@data)] <- 'sst'

# HMSC data
    studyGrid <- egsl_grid@data

    envCov <-  c('bathy','sst')

# Remove environmental NAs
    NAs <- studyGrid[, envCov] %>%
            lapply(X = ., FUN = function(x) which(is.na(x))) %>%
            unlist(.) %>%
            unique(.)
    NAsID <- studyGrid[NAs,'ID']

    studyGrid <- studyGrid[-NAs, ]
```

<br/>

##### Create HMSC class data

<br/>

```{r, HMSC data, eval = FALSE}
# ---------------------------------
# Y: sample units by species matrix
# ---------------------------------
# Extracting only presence/absence data
    Station <- studyGrid[, 'ID']
    Y <- studyGrid[, as.character(spID)]
    rownames(Y) <- Station

    for(i in 1:ncol(Y)) {
        Y[,i] <- as.numeric(as.character(Y[,i]))
    }

# -----------------------------------------
# Pi: sample units by random effects matrix
# -----------------------------------------
# Create a dataframe for random effects, columns have to be factors
    Pi <- data.frame(sampling_unit = as.factor(Station))

# ----------------------------------------------------
# X: sampling units by environmental covariates matrix
# ----------------------------------------------------
# Create a matrix for the values of environmental covariates at each sampling unit location
    X <- matrix(ncol = length(envCov),
                nrow = nrow(studyGrid))
    X <- studyGrid[, envCov]
            rownames(X) <- Station

# ----------------------------
# as.HMSCdata for HMSC package
# ----------------------------
# Creating HMSC dataset for analyses
    HMSCdata <- HMSC::as.HMSCdata(Y = Y, X = X, Random = Pi, interceptX = T, scaleX = T)
    str(HMSCdata)
```

<br/>

##### HMSC analysis

We are now ready to perform the analyses!

```{r, HMSC model, eval = FALSE}
model <- HMSC::hmsc(HMSCdata,
                    family = "probit",
                    niter = 10000,
                    nburn = 100,
                    thin = 10)
saveRDS(model, file = './HMSCmodel.rds')
```

<br/>

##### HMSC analysis diagnostics

```{r, MCMC sampling, eval = FALSE}
model <- readRDS('./HMSCmodel.rds')
# =========================================
# 3. Producing MCMC trace and density plots
# =========================================
    mixingMeansParamX <- coda::as.mcmc(model, parameters = "meansParamX")

# Trace and density plots to visually diagnose mcmc chains
# Another way to check for convergence is to use diagnostic tests such as Geweke's convergence diagnostic (geweke.diag function in coda) and the Gelman and Rubin's convergence diagnostic (gelman.diag function in coda).
    paramModel <- colnames(mixingMeansParamX)
    nParam <- length(paramModel)

    par(mfrow = c(nParam, 2), mar = rep(2, 4))
    for(i in 1:ncol(mixingMeansParamX)) {
      coda::traceplot(mixingMeansParamX[,i], col = "blue", main = paste('Trace of ', paramModel[i]))
      coda::densplot(mixingMeansParamX[,i], col = "orange", main = paste('Density of ', paramModel[i]))
    }
```

<br/>

```{r, posterior summaries, eval = FALSE}
# ================================
# 4. Producing posterior summaries
# ================================
# Average
    average <- apply(model$results$estimation$paramX, 1:2, mean)
# 95% confidence intervals
    CI.025 <- apply(model$results$estimation$paramX, 1:2, quantile, probs = 0.025)
    CI.975 <- apply(model$results$estimation$paramX, 1:2, quantile, probs = 0.975)

# Summary table
    paramXCITable <- cbind(unlist(as.data.frame(average)),
                         unlist(as.data.frame(CI.025)),
                         unlist(as.data.frame(CI.975)))
    colnames(paramXCITable) <- c("average", "lowerCI", "upperCI")
    rownames(paramXCITable) <- paste(rep(colnames(average), each = nrow(average)), "_", rep(rownames(average), ncol(average)), sep="")

# Credible intervals
    paramXCITable_Full <- paramXCITable

    beg <- seq(1,nrow(paramXCITable_Full), by = nsp)
    end <- seq(nsp,nrow(paramXCITable_Full), by = nsp)
    sign <- abs(as.numeric(paramXCITable_Full[, 'lowerCI'] <= 0 & paramXCITable_Full[, 'upperCI'] >=0) - 3)

# Export figure
    par(mfrow = c((length(beg)+1),1))
    for(i in 1:length(beg)) {
        paramXCITable <- paramXCITable_Full[beg[i]:end[i], ]
        cols <- sign[beg[i]:end[i]]
        par(mar=c(1,2,1,1))
        plot(0, 0, xlim = c(1, nrow(paramXCITable)), ylim = round(range(paramXCITable)), type = "n", xlab = "", ylab = "", main=paste(colnames(mixingMeansParamX)[i]), xaxt="n", bty = 'n')
        axis(1,1:nsp,las=2, labels = rep('',nsp))
        abline(h = 0,col = 'grey')
        arrows(x0 = 1:nrow(paramXCITable), x1 = 1:nrow(paramXCITable), y0 = paramXCITable[, 2], y1 = paramXCITable[, 3], code = 3, angle = 90, length = 0.05, col = cols)
        points(1:nrow(paramXCITable), paramXCITable[,1], pch = 15, cex = 1, col = cols)
    }
    mtext(text = spAll, side = 1, line = 1, outer = FALSE, at = 1:nsp, col = 1, las = 2, cex = 0.4)
```

<br/>

```{r, association networks, eval = FALSE}
# =======================
# 6. Association networks
# =======================
# Extract all estimated associatin matrix
    assoMat <- HMSC::corRandomEff(model)

# Average
    plotMean <- apply(assoMat[, , , 1], 1:2, mean)
    colnames(plotMean) <- rownames(plotMean) <- spAll

# Build matrix of colours for chordDiagram
    plotDrawCol <- matrix(NA, nrow = nrow(plotMean), ncol = ncol(plotMean))
    plotDrawCol[which(plotMean > 0.4, arr.ind=TRUE)]<-"red"
    plotDrawCol[which(plotMean < -0.4, arr.ind=TRUE)]<-"blue"
# Build matrix of "significance" for corrplot
    plotDraw <- plotDrawCol
    plotDraw[which(!is.na(plotDraw), arr.ind = TRUE)] <- 0
    plotDraw[which(is.na(plotDraw), arr.ind = TRUE)] <- 1
    plotDraw <- matrix(as.numeric(plotDraw), nrow = nrow(plotMean), ncol = ncol(plotMean))

# plots
    jpeg('./Pictures/correlationPlot.jpeg', width = 7, height = 7, res = 150, units = 'in')
    # Matrix plot
    Colour <- colorRampPalette(c("red", "white", "blue"))(200)
    corrplot::corrplot(plotMean, method = "color", col = Colour, type = "lower", diag = FALSE, p.mat = plotDraw, tl.srt = 65, tl.cex = 0.4, pch.cex = 0.3, tl.col = 'black')

    # Chord diagram
    circlize::chordDiagram(plotMean, symmetric = TRUE, annotationTrack = 'grid', grid.col = "grey", col = plotDrawCol, preAllocateTracks = 1)
    circlize::circos.trackPlotRegion(track.index = 1, panel.fun = function(x, y) {
      xlim = circlize::get.cell.meta.data("xlim")
      ylim = circlize::get.cell.meta.data("ylim")
      sector.name = circlize::get.cell.meta.data("sector.index")
      circlize::circos.text(mean(xlim), ylim[1] + .1, sector.name, facing = "clockwise", niceFacing = TRUE, adj = c(0, 0.5), cex = 0.4)
    }, bg.border = NA)
    dev.off()
```

<br/>

[](https://github.com/remi-daigle/2017-CHONe-Data/tree/gh-pages/pictures/correlationPlot.jpeg)

<br/>

```{r, predictive power, eval = FALSE}
    # ===============================================
    # 7. Computing the explanatory power of the model
    # ===============================================
        # Prevalence
            prevSp <- colSums(HMSCdata$Y)
        # Coefficient of multiple determination
            R2 <- HMSC::Rsquared(model, averageSp = FALSE)

        # Draw figure
            plot(prevSp, R2, xlab = "Prevalence", ylab = expression(R^2), cex = 0.8, pch=19, las=1, cex.lab = 1, main = 'Explanatory power of the model')
            abline(h = mean(R2, na.rm = T), col = "blue", lwd = 2)
```

<br/>

```{r, AUC, eval = FALSE}
    # =============================================
    # 8. Generating predictions for validation data
    # =============================================
        source('./crossValid.r')
        modelAUC <- crossValidation(data = HMSCdata,  nCV = 2, validPct = 0.2, as.strata = FALSE)
        saveRDS(modelAUC, './modelAUC.rds')
```

```{r, AUC2, eval = FALSE}
        modelAUC <- readRDS('./modelAUC.rds')
        meanAUC <- colMeans(modelAUC)
        sdAUC <- apply(modelAUC, MARGIN = 2, FUN = sd)

        plot(prevSp, meanAUC, ylim = c(0,1), xlab = "Prevalence", ylab = 'AUC', cex = 0.8, pch=19, las=1, cex.lab = 1, main = 'Monte Carlo cross-validation with AUC of ROC curves')
        abline(h = 0.5, col = 'grey')
        arrows(x0 = prevSp, x1 = prevSp, y0 = (meanAUC - sdAUC), y1 = (meanAUC + sdAUC), code = 3, angle = 90, length = 0.05)
        points(prevSp, meanAUC, pch = 19, cex = 0.8)
```

<br/>

```{r, predictions, eval = FALSE}
# Generate predictions
    HMSCpred <- predict(model)

# Replace NAs in grid
    data <- matrix(nrow = (length(NAs) + nrow(HMSCpred)), ncol = ncol(HMSCpred), data = 0)
    dimnames(data) = list(paste('ID',seq(1:nrow(data)), sep = ''), colnames(HMSCpred))

    for(i in 1:length(NAsID)) {
        data[which(rownames(data) == NAsID[i]), ] <- NA
    }

    for(i in 1:nrow(HMSCpred)) {
        data[which(rownames(data) == rownames(HMSCpred)[i]), ] <- HMSCpred[i, ]
    }

    HMSCpred <- data
    HMSCpred <- cbind(HMSCpred, rownames(HMSCpred))
    colnames(HMSCpred)[ncol(HMSCpred)] <- 'ID'
    # colnames(HMSCpred) <- spAll
```

<br/>

```{r, plotPred, eval = FALSE, message = FALSE}
# Plot grid
    egsl_grid <- rgdal::readOGR(dsn = "./", layer = "egsl_grid")
    proj <- "+proj=longlat +datum=WGS84"
    egsl_grid <- sp::spTransform(egsl_grid, CRSobj = CRS(proj))


    egsl_grid@data <- merge(egsl_grid@data, HMSCpred, by = 'ID')

    data <- egsl_grid@data[,31]
    rbPal <- colorRampPalette(c('#2f6eb9','#2aadba','#b45f5f')) # color palette
    cols <- rbPal(50)[as.numeric(cut(as.numeric(data), breaks = 50))]
    plot(egsl_grid, col = cols, border = cols)
```

<br/>

-->
